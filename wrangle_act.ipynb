{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Project: Data Wrangling ( WeRateDogs)\n",
    "\n",
    "## Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#intro\">Introduction</a></li>\n",
    "<li><a href=\"#gathering\">Gathering Data</a></li>\n",
    "<li><a href=\"#assess\">Assissing Data</a></li>\n",
    "<li><a href=\"#observ\">Observations</a></li>\n",
    "<li><a href=\"#conclusion\">Conclusions</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "The dataset the we will analyse is the tweet archive of Twitter user @dog_rates, also known as WeRateDogs. WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10. <br/>\n",
    "In this project we will analyze and visualize date and extrat insights about this data, but before that we should check data for quality and tideness to be able to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import the libraries needed for this project\n",
    "import pandas as pd\n",
    "import requests as request\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns;\n",
    "import numpy as np;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gathering'></a>\n",
    "## Gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read twitter-archive file\n",
    "df_archive = pd.read_csv('data/twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download image predictions file programatically\n",
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "response = request.get(url)\n",
    "response.content\n",
    "with open(os.path.join('data/' + url.split('/')[-1]), 'wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data/image-predictions.tsv after downloading\n",
    "df_image = pd.read_csv('data/image-predictions.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/tweet-json.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-4ad82af2a9ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# so I will read data from tweet_json directly without twitter API\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/tweet-json.txt'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mdf_twitter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/tweet-json.txt'"
     ]
    }
   ],
   "source": [
    "# unfortuntly I have tried to register for twitter developer account but I have got refused message \n",
    "# ( Your Twitter developer account application was not approved.)\n",
    "# so I will read data from tweet_json directly without twitter API\n",
    "\n",
    "with open('data/tweet-json.txt') as file:\n",
    "    df_twitter = pd.read_json(file, lines= True, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image-predictions.tsv', 'tweet-json copy', 'twitter-archive-enhanced.csv']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assess'></a>\n",
    "## Assess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess twitter-archiv, select different samples to spot issues \n",
    "df_archive.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check source columns\n",
    "df_archive.source.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check names\n",
    "df_archive.name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive['rating_numerator'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive['rating_denominator'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.rating_numerator.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for duplication\n",
    "df_archive[df_archive.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive[df_archive.tweet_id==10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_image[df_image.p1_dog==True].p1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image[df_image['p1']=='orange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image[df_image.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter['user'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = pd.Series(list(df_archive)+ list(df_image)+ list(df_twitter))\n",
    "all_columns[all_columns.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "### Quality\n",
    "\n",
    "##### twitter_archive table: \n",
    "\n",
    "1. tweet_id should be string, not integer.\n",
    "2. Sores with (.) read incorrectly, we need to read the correct value from text column.\n",
    "3. rating denamator values should be 10, there is values other than 10\n",
    "4. timestamp in archive is object, should convert it to datetime\n",
    "5. columns (doggo,floofer,pupper,puppo) have None instead of NaN\n",
    "6. souce column have full html link, we are intrested only in values (iphone, ....)\n",
    "7. missing names (None), and invalid names (a, an, O, the ....)\n",
    "8. some dog has 2 stages (example tweet_id = '' has floofer and doggo)\n",
    "9. retweets (text starting with RT @) should be removed.\n",
    "\n",
    "##### image-prediction table: \n",
    "9. missing records, 2075 instead of 2355.\n",
    "\n",
    "\n",
    "##### twitter table: \n",
    "10. id columns should be rename to (twitter_id)\n",
    "\n",
    "### Tideness\n",
    "\n",
    "##### twitter_archive table: \n",
    "1. df_archive table: columns (doggo,floofer,pupper,puppo) are dogs stages, sould be in one columns (dog_stage)\n",
    "\n",
    "##### twitter table: \n",
    "2. Columns (source , text) are also exists in df_archive table, so we can remove them, also we are only interested in only 3 columns (id, retweet_count, favorite_count), so we can remove all other columns\n",
    "3. all 3 tables should be combined into one table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean\n",
    "### A. Fixing Quality Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Firstly, Lets take a copy from our data so we can keep the original ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_copy = df_archive.copy()\n",
    "df_image_copy = df_image.copy()\n",
    "df_tweeter_copy = df_twitter.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.\n",
    "#### Define\n",
    "\n",
    "convert tweet_id into string in df_archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_copy['tweet_id'] = df_archive_copy['tweet_id'].astype(str)\n",
    "df_image_copy['tweet_id'] = df_image_copy['tweet_id'].astype(str)\n",
    "df_twitter['id'] = df_twitter['id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_copy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\n",
    "#### Define\n",
    "Sores with (.) read incorrectly, we need to read the correct value from text column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_archive_copy[df_archive_copy.text.str.contains(r\"(\\d+\\.\\d+\\/\\d+)\")][['text', 'rating_numerator']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# extact number before point and drop the numbers after points\n",
    "extracted_score_df = \\\n",
    "    df_archive_copy[df_archive_copy.text.str.contains(r\"(\\d+\\.\\d+\\/\\d+)\")].text.str.extract(r\"(\\d+)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_copy.loc[extracted_score_df.index, 'rating_numerator'] = extracted_score_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_copy.rating_numerator = df_archive_copy.rating_numerator.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_archive_copy[df_archive_copy.text.str.contains(r\"(\\d+\\.\\d+\\/\\d+)\")][['text', 'rating_numerator']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.\n",
    "### Define\n",
    "rating denamator values should be 10, there is values other than 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_copy[df_archive_copy.rating_denominator != 10].rating_denominator.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set denominator to 10\n",
    "df_archive_copy.loc[df_archive_copy.rating_denominator != 10,'rating_denominator'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_copy[df_archive_copy.rating_denominator != 10].rating_denominator.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.\n",
    "### Define\n",
    "timestamp in archive is object, should convert it to time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_copy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_copy['timestamp'] = pd.to_datetime(df_archive_copy.timestamp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_copy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.\n",
    "### Define\n",
    "columns (doggo,floofer,pupper,puppo) have None instead of NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_copy[df_archive_copy.doggo == 'None']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace None with np.nan\n",
    "df_archive_copy.loc[df_archive_copy.doggo == 'None', 'doggo'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_copy.loc[df_archive_copy.floofer == 'None', 'floofer'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_copy.loc[df_archive_copy.pupper == 'None', 'pupper'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_copy.loc[df_archive_copy.puppo == 'None', 'puppo'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_copy[['doggo', 'floofer','pupper','puppo']].head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.\n",
    "### Define\n",
    "souce column have full html link, we are intrested only in values (iphone, ....) and convert it into categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_archive_copy.source.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gettext(str1):\n",
    "    start = str1.find(\">\")+1\n",
    "    end = str1.find(\"<\", start)\n",
    "    return str1[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_archive_copy = df_archive.copy()\n",
    "df_archive_copy.source = df_archive_copy.source.astype('str').apply(lambda x: gettext(x)).astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_copy.source.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.\n",
    "### Define\n",
    "Remove retweets and replies (retweet count and favorite count are two of the notable column omissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "cols = ['in_reply_to_status_id','in_reply_to_user_id','retweeted_status_id',\n",
    "           'retweeted_status_user_id', 'retweeted_status_timestamp']\n",
    "df_archive_copy.drop(columns = cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_copy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_copy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.\n",
    "### Define\n",
    "remove rows which not related to dogs, (the text declare .*only rate dogs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_copy = df_archive_copy.loc[~df_archive_copy.text.str.match('.*only rate dogs', na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_copy[df_archive_copy.text.str.match('.*only rate dogs', na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.\n",
    "### Define\n",
    "removing retweets (text starting with RT @)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_copy = df_archive_copy[~df_archive_copy.text.str.match('RT @', na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_copy[df_archive_copy.text.str.match('RT @', na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Fixing Tidiness Issues\n",
    "\n",
    "## 1.\n",
    "### Define\n",
    "\n",
    "remove unnecessary columns, keep only 3 column which we intrest in our analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweeter_copy = df_tweeter_copy[['id', 'retweet_count', 'favorite_count']]\n",
    "\n",
    "#rename id to tweet_id\n",
    "\n",
    "df_tweeter_copy.rename(columns = {'id':'tweet_id'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert tweet_id into string\n",
    "df_tweeter_copy.tweet_id = df_tweeter_copy.tweet_id.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweeter_copy.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\n",
    "### Define\n",
    "melt columns ('doggo', 'floofer', 'pupper', 'puppo') into categarical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_archive_copy = df_archive.copy()\n",
    "df_archive_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_copy.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_archive_copy)):\n",
    "    if not(df_archive_copy.loc[i, \"doggo\"] is np.nan): \n",
    "        df_archive_copy.loc[i, \"stage\"] = df_archive_copy.loc[i, \"doggo\"]\n",
    "        #print(i, \"doggo\", df_archive_copy.loc[i])\n",
    "    elif not(df_archive_copy.loc[i, \"floofer\"] is np.nan): \n",
    "        df_archive_copy.loc[i, \"stage\"] = df_archive_copy.loc[i, \"floofer\"]\n",
    "        #print(i, \"floofer\", df_archive_copy.loc[i])\n",
    "    elif not(df_archive_copy.loc[i, \"pupper\"] is np.nan): \n",
    "        df_archive_copy.loc[i, \"stage\"] = df_archive_copy.loc[i, \"pupper\"]\n",
    "        #print(i, \"pupper\", df_archive_copy.loc[i])\n",
    "    elif not(df_archive_copy.loc[i, \"puppo\"] is np.nan): \n",
    "        df_archive_copy.loc[i, \"stage\"] = df_archive_copy.loc[i, \"puppo\"]\n",
    "        #print(i, \"puppo\", df_archive_copy.loc[i])\n",
    "    else:\n",
    "        df_archive_copy.loc[i, \"stage\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the extra columns  ('doggo', 'floofer', 'pupper', 'puppo')\n",
    "df_archive_copy = df_archive_copy.drop(['doggo','floofer','pupper','puppo'] , axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_copy.stage.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.\n",
    "### Define\n",
    "Merge 3 tables into one table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.merge(df_archive_copy, df_image_copy, on = 'tweet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.merge(df_clean, df_tweeter_copy, on = 'tweet_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='observ'></a>\n",
    "# Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "data = df_archive_copy.rating_numerator.value_counts()\n",
    "data = data[data.index < 20]\n",
    "sns.barplot(data.index, data.values, palette='Greens_d',ax=ax)\n",
    "ax.set(xlabel='Ratings', ylabel='Frequency', title='Ratings frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_archive_copy.stage.value_counts()\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(12, 6))\n",
    "explode = (0.0, 0.0, 0, 0)  \n",
    "ax1.pie(data.values, explode=explode, labels=data.index, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=-50)\n",
    "# Equal aspect ratio ensures that pie is drawn as a circle\n",
    "ax1.axis('equal')  \n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.title(\"Dog Stages Percentage\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "data = df_archive_copy.source.value_counts()\n",
    "sns.barplot(y=data.index, x=data.values, palette='Greens_d',ax=ax)\n",
    "ax.set(xlabel='Tweet Source', ylabel='Total', title='Tweet Source Totals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_clean.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "df_clean['month'] = df_clean['timestamp'].apply(lambda x:x.strftime('%Y-%m'))\n",
    "\n",
    "data =  df_clean.groupby('month')[['retweet_count', 'favorite_count']].aggregate(np.sum)\n",
    "data = data.drop('2017-08')\n",
    "\n",
    "plt.plot(data.index, data.values)\n",
    "\n",
    "plt.grid()\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(['retweet_count', 'favorite_count'])\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusion'></a>\n",
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after analysing WeRateDog Data we conclude : <br/>\n",
    "1. percentage of pupper stage is most populate with 64% of total tweets, next is doggo with 25%.\n",
    "2. most people use (Twitter for iphone) for twetter.\n",
    "3. looking at trend, number of favorets and retweet generally increasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving Cleaned data into twitter_archive_enhanced.csv\n",
    "df_clean.to_csv(\"twitter_archive_master.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
